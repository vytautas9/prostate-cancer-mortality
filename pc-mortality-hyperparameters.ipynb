{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebook to test and find best hyperparameters for various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: 15664\n",
      "Number of CPUs in the system: 16\n",
      "executing command 'taskset -cp 0,1,2,3,4,5,6,7,8,9,10,11,12,13 15664' ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pid = os.getpid()\n",
    "print(\"PID: %i\" % pid)\n",
    "\n",
    "n_cpu = os.cpu_count()   # Number of CPUs assigned to this process\n",
    "print(\"Number of CPUs in the system:\", n_cpu)\n",
    "\n",
    "# we won't use all the available cpu's for this script \n",
    "n_jobs = n_cpu - 2 # The number of tasks to run in parallel\n",
    "\n",
    "# Control which CPUs are made available for this script\n",
    "cpu_arg = ''.join([str(ci) + ',' for ci in list(range(n_jobs))])[:-1]\n",
    "cmd = 'taskset -cp %s %i' % (cpu_arg, pid)\n",
    "print(\"executing command '%s' ...\" % cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to cleaned data file\n",
    "trainFilePath = 'data/data_train.pkl'\n",
    "\n",
    "# Read already prepared and saved train datasets\n",
    "with open(trainFilePath, 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "\n",
    "# Create dummy variables for categorical data\n",
    "data_train = pd.get_dummies(data_train, columns=['clinical_stage', 'biopsy_gleason_gg', 'pathological_gleason_gg',\n",
    "                                'pathologic_stage', 'lni', 'surgical_margin_status', 'persistent_psa',\n",
    "                                'TRYSgrupes', 'PLNDO1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explodes the provided \"df\" dataset based on provided survival column \"time\" and\n",
    "clips the data to be in a range [min_time; max_time] (). A new discrete survival column\n",
    "will be created with name set as variable \"time_discrete\". \"cum_event\" boolean determines\n",
    "if cumulative event column will be created or no.\n",
    "\n",
    "clip(lower, upper) function will help us create a new discrete survival time column. \n",
    "If we specify lower=1 and upper=200, patients who experienced event earlier than 200th \n",
    "month will only have records till their event, on other side, if a patient survived past \n",
    "200th month, we will clip this information and will only keep information about him til 200th month.\n",
    "Another example, if we specify lower=140 and upper=200, and if the person experienced event \n",
    "at 100th month, we will create records for him till 140th (lower boundary) month.\n",
    "\"\"\"\n",
    "def explode_data(df,max_time,time,target_column,min_time=1,\n",
    "                 time_discrete='survival_time_discrete',cum_event=False):\n",
    "\n",
    "    target_column_discrete = target_column + '_discrete'\n",
    "\n",
    "    # We create a new time column and clip the data by provided min and max survival times\n",
    "    df[time_discrete] = df[time].clip(min_time,max_time).apply(range)\n",
    "\n",
    "    # Exploding the dataset with the created range value in new time column\n",
    "    data_exploded = df.explode(time_discrete)\n",
    "    data_exploded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # New column starts at 0, we'll increase each value by 1\n",
    "    data_exploded[time_discrete] = pd.to_numeric(data_exploded[time_discrete]) + 1\n",
    "\n",
    "    # New event column, which will indicate the last event date\n",
    "    data_exploded[target_column_discrete] = (data_exploded[time_discrete] >= data_exploded[time]) * pd.to_numeric(data_exploded[target_column])\n",
    "    \n",
    "    if cum_event == True:\n",
    "        target_column_cumulative = target_column + '_cumulative'\n",
    "\n",
    "        # Create new event column with duplicated event values from discrete column\n",
    "        data_exploded[target_column_cumulative] = data_exploded[target_column_discrete]\n",
    "        \n",
    "        # For cumulative events, after end_time we will have NA values, we'll replace those with event indicator\n",
    "        after_survival_time = data_exploded[time_discrete] > data_exploded[time]\n",
    "        data_exploded.loc[after_survival_time, target_column_discrete] = -1\n",
    "        data_exploded[target_column_discrete] = data_exploded[target_column_discrete].replace(-1,np.NaN)\n",
    "        data_exploded.loc[(after_survival_time & (data_exploded[target_column]==0)), target_column_cumulative] = -1\n",
    "        data_exploded[target_column_cumulative] = data_exploded[target_column_cumulative].replace(-1,np.NaN)\n",
    "\n",
    "    return data_exploded\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given an exploded dataset with instant mortality probabilities \"event_probability_column\"\n",
    "and \"id_column\" for grouping (optional), cumulative hazard column will be calculated\n",
    "\"\"\"\n",
    "def cumulative_hazard(df, event_probability_column, id_column):\n",
    "    data_copy = df.copy()\n",
    "    if id_column is not None:\n",
    "        data_copy = data_copy[ [id_column, event_probability_column] ]\n",
    "    else:\n",
    "        data_copy = data_copy[ [event_probability_column] ]\n",
    "    data_copy['negative_log_prob'] = np.log( 1 - data_copy[event_probability_column] )\n",
    "    if id_column is not None:\n",
    "        data_copy['cumulative_hazard'] = 1 - np.exp(data_copy.groupby(id_column)['negative_log_prob'].transform(pd.Series.cumsum))\n",
    "    else:\n",
    "        data_copy['cumulative_hazard'] = 1 - np.exp(data_copy['negative_log_prob'].cumsum())\n",
    "    return data_copy['cumulative_hazard']\n",
    "\n",
    "\n",
    "\n",
    "def add_predict_probabilities_optimized(df_exploded, target_column, model):\n",
    "    \"\"\"\n",
    "    Given exploded datase. Adds predictend instant mortality probabilities as well as cumulative ones.\n",
    "    \"\"\"\n",
    "\n",
    "    df_exploded_copy = df_exploded.copy()\n",
    "    df_exploded_copy.drop(['patient_id', target_column + '_cumulative'], axis=1, inplace=True)\n",
    "    \n",
    "    # probabilities\n",
    "    y_pred = model.predict_proba(df_exploded_copy)[:,1]\n",
    "    df_exploded['mortality_instant_prob'] = y_pred\n",
    "\n",
    "    # Cumulative hazard for each patient\n",
    "    df_exploded['cumulative_hazard'] = cumulative_hazard(df_exploded,'mortality_instant_prob','patient_id')\n",
    "    \n",
    "    return df_exploded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cancer specific mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'cancer_specific_mortality'\n",
    "max_time = 200\n",
    "\n",
    "# mts and bcr have different survival months columns\n",
    "match target_column:\n",
    "    case 'mts':\n",
    "        time = 'survival_months_mts'\n",
    "    case 'bcr':\n",
    "        time = 'survival_months_bcr'\n",
    "    case _:\n",
    "        time = 'survival_months'\n",
    "\n",
    "target_column_discrete = target_column + '_discrete'\n",
    "\n",
    "# List of columns names which will be dropped from feature set before fitting the model\n",
    "target_columns = ['cancer_specific_mortality', 'death_from_other_causes', 'bcr', 'mts']\n",
    "\n",
    "# Explode the dataset\n",
    "df_train_copy_exploded = explode_data(data_train.copy(), min_time=1, max_time=max_time, time=time, target_column=target_column)\n",
    "\n",
    "# Drop targets/features from feature set\n",
    "x_columns_to_drop = [target_column_discrete, 'survival_months', 'survival_months_bcr', 'survival_months_mts', 'patient_id']\n",
    "x_columns_to_drop.extend(target_columns)\n",
    "X_train = df_train_copy_exploded.drop(x_columns_to_drop, axis=1)    \n",
    "y_train = df_train_copy_exploded[target_column_discrete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>psa</th>\n",
       "      <th>biopsy_gleason</th>\n",
       "      <th>pathologic_gleason</th>\n",
       "      <th>bcr</th>\n",
       "      <th>mts</th>\n",
       "      <th>death_from_other_causes</th>\n",
       "      <th>clinical_stage_1</th>\n",
       "      <th>clinical_stage_2</th>\n",
       "      <th>clinical_stage_3</th>\n",
       "      <th>...</th>\n",
       "      <th>surgical_margin_status_0</th>\n",
       "      <th>surgical_margin_status_1</th>\n",
       "      <th>persistent_psa_0</th>\n",
       "      <th>persistent_psa_1</th>\n",
       "      <th>TRYSgrupes_0</th>\n",
       "      <th>TRYSgrupes_1</th>\n",
       "      <th>TRYSgrupes_2</th>\n",
       "      <th>PLNDO1_0</th>\n",
       "      <th>PLNDO1_1</th>\n",
       "      <th>survival_time_discrete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.0</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.0</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.0</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73.0</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.0</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250195</th>\n",
       "      <td>68.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250196</th>\n",
       "      <td>68.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250197</th>\n",
       "      <td>68.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250198</th>\n",
       "      <td>68.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250199</th>\n",
       "      <td>68.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250200 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age   psa  biopsy_gleason  pathologic_gleason bcr mts  \\\n",
       "0       73.0  6.36             6.0                 7.0   1   0   \n",
       "1       73.0  6.36             6.0                 7.0   1   0   \n",
       "2       73.0  6.36             6.0                 7.0   1   0   \n",
       "3       73.0  6.36             6.0                 7.0   1   0   \n",
       "4       73.0  6.36             6.0                 7.0   1   0   \n",
       "...      ...   ...             ...                 ...  ..  ..   \n",
       "250195  68.0  6.00             6.0                 8.0   1   0   \n",
       "250196  68.0  6.00             6.0                 8.0   1   0   \n",
       "250197  68.0  6.00             6.0                 8.0   1   0   \n",
       "250198  68.0  6.00             6.0                 8.0   1   0   \n",
       "250199  68.0  6.00             6.0                 8.0   1   0   \n",
       "\n",
       "       death_from_other_causes  clinical_stage_1  clinical_stage_2  \\\n",
       "0                            0                 0                 0   \n",
       "1                            0                 0                 0   \n",
       "2                            0                 0                 0   \n",
       "3                            0                 0                 0   \n",
       "4                            0                 0                 0   \n",
       "...                        ...               ...               ...   \n",
       "250195                       0                 0                 1   \n",
       "250196                       0                 0                 1   \n",
       "250197                       0                 0                 1   \n",
       "250198                       0                 0                 1   \n",
       "250199                       0                 0                 1   \n",
       "\n",
       "        clinical_stage_3  ...  surgical_margin_status_0  \\\n",
       "0                      1  ...                         0   \n",
       "1                      1  ...                         0   \n",
       "2                      1  ...                         0   \n",
       "3                      1  ...                         0   \n",
       "4                      1  ...                         0   \n",
       "...                  ...  ...                       ...   \n",
       "250195                 0  ...                         0   \n",
       "250196                 0  ...                         0   \n",
       "250197                 0  ...                         0   \n",
       "250198                 0  ...                         0   \n",
       "250199                 0  ...                         0   \n",
       "\n",
       "        surgical_margin_status_1  persistent_psa_0  persistent_psa_1  \\\n",
       "0                              1                 1                 0   \n",
       "1                              1                 1                 0   \n",
       "2                              1                 1                 0   \n",
       "3                              1                 1                 0   \n",
       "4                              1                 1                 0   \n",
       "...                          ...               ...               ...   \n",
       "250195                         1                 1                 0   \n",
       "250196                         1                 1                 0   \n",
       "250197                         1                 1                 0   \n",
       "250198                         1                 1                 0   \n",
       "250199                         1                 1                 0   \n",
       "\n",
       "        TRYSgrupes_0  TRYSgrupes_1  TRYSgrupes_2  PLNDO1_0  PLNDO1_1  \\\n",
       "0                  0             1             0         1         0   \n",
       "1                  0             1             0         1         0   \n",
       "2                  0             1             0         1         0   \n",
       "3                  0             1             0         1         0   \n",
       "4                  0             1             0         1         0   \n",
       "...              ...           ...           ...       ...       ...   \n",
       "250195             0             0             1         1         0   \n",
       "250196             0             0             1         1         0   \n",
       "250197             0             0             1         1         0   \n",
       "250198             0             0             1         1         0   \n",
       "250199             0             0             1         1         0   \n",
       "\n",
       "        survival_time_discrete  \n",
       "0                            1  \n",
       "1                            2  \n",
       "2                            3  \n",
       "3                            4  \n",
       "4                            5  \n",
       "...                        ...  \n",
       "250195                     196  \n",
       "250196                     197  \n",
       "250197                     198  \n",
       "250198                     199  \n",
       "250199                     200  \n",
       "\n",
       "[250200 rows x 36 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators':np.arange(150,700,50),\n",
    "              'max_features':np.arange(0.1, 1, 0.1),\n",
    "              'max_depth': [3, 5, 7, 9],\n",
    "              'max_samples': [0.3, 0.5, 0.8],\n",
    "              'min_samples_leaf': [1, 2, 3, 4, 5]}\n",
    "\n",
    "rf_random = RSCV(RandomForestClassifier(), param_grid, n_iter=15, \n",
    "             random_state=0, verbose=2, scoring='roc_auc', n_jobs=n_jobs)\n",
    "model_rf = rf_random.fit(X_train, y_train)\n",
    "model_rf_best = model_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_leaf': 5,\n",
       " 'max_samples': 0.3,\n",
       " 'max_features': 0.5,\n",
       " 'max_depth': 3}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters\n",
    "model_rf.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cancer specific mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'cancer_specific_mortality'\n",
    "max_time = 216\n",
    "\n",
    "# mts and bcr have different survival months columns\n",
    "match target_column:\n",
    "    case 'mts':\n",
    "        time = 'survival_months_mts'\n",
    "    case 'bcr':\n",
    "        time = 'survival_months_bcr'\n",
    "    case _:\n",
    "        time = 'survival_months'\n",
    "\n",
    "target_column_discrete = target_column + '_discrete'\n",
    "\n",
    "# List of columns names which will be dropped from feature set before fitting the model\n",
    "target_columns = ['cancer_specific_mortality', 'death_from_other_causes', 'bcr', 'mts']\n",
    "\n",
    "# Explode the dataset\n",
    "df_train_copy_exploded = explode_data(data_train.copy(), min_time=1, max_time=max_time, time=time, target_column=target_column)\n",
    "\n",
    "# Drop targets/features from feature set\n",
    "x_columns_to_drop = [target_column, target_column_discrete, 'survival_months', 'survival_months_bcr', 'survival_months_mts', 'patient_id']\n",
    "x_columns_to_drop.extend(target_columns)\n",
    "X_train = df_train_copy_exploded.drop(x_columns_to_drop, axis=1)    \n",
    "y_train = df_train_copy_exploded[target_column_discrete]\n",
    "\n",
    "df_train_copy_exploded_cumulative = explode_data(data_train.copy(), max_time=max_time, min_time=max_time, cum_event=True, time=time, target_column=target_column)\n",
    "x_columns_to_drop_exploded_cumulative = [target_column+'_discrete', 'survival_months', 'survival_months_bcr', 'survival_months_mts']\n",
    "x_columns_to_drop_exploded_cumulative.extend(target_columns)\n",
    "df_train_copy_exploded_cumulative = df_train_copy_exploded_cumulative.drop(x_columns_to_drop_exploded_cumulative, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
    "        'max_depth': hp.uniform('max_depth',5,20),\n",
    "        'max_features': hp.choice('max_features', ['sqrt','log2', None]),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
    "        'n_estimators' : hp.uniform('n_estimators', 100, 500)\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = int(space['max_depth']),\n",
    "                                 max_features = space['max_features'],\n",
    "                                 min_samples_leaf = space['min_samples_leaf'],\n",
    "                                 min_samples_split = space['min_samples_split'],\n",
    "                                 n_estimators = int(space['n_estimators']), \n",
    "                                 )\n",
    "    \n",
    "    # fit the data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # add predicted probabilities\n",
    "    df_train_copy_exploded_pred = add_predict_probabilities_optimized(df_train_copy_exploded_cumulative.copy(), target_column, model)\n",
    "    \n",
    "    # calculate auc\n",
    "    # AUC for each cumulative slice\n",
    "    # Months at which we'll check the AUC's\n",
    "    months = list(range(6, max_time, 6))\n",
    "\n",
    "    train_auc_stats = []\n",
    "    for month in months:\n",
    "        # --- Training data ---\n",
    "        # Selecting a subset of data based on the months\n",
    "        select = (df_train_copy_exploded_pred['survival_time_discrete'] == month) & pd.notna(df_train_copy_exploded_pred[target_column+'_cumulative'])\n",
    "        sub_dat = df_train_copy_exploded_pred[select]\n",
    "\n",
    "        # If in the sliced data there's a event, calculate AUC metric,\n",
    "        # otherwise assign NaN value\n",
    "        if sub_dat[target_column+'_cumulative'].max() == 1:\n",
    "            fpr, tpr, thresholds = roc_curve(sub_dat[target_column+'_cumulative'], sub_dat['cumulative_hazard'])\n",
    "            auc_stat = auc(fpr, tpr)\n",
    "        else:\n",
    "            auc_stat = float('NaN')\n",
    "        train_auc_stats.append(auc_stat)\n",
    "\n",
    "    auc_mean = np.nanmean(train_auc_stats)\n",
    "\n",
    "    # We aim to maximize auc, therefore we return it as a negative value\n",
    "    return {'loss': -auc_mean, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:09<00:00,  6.91s/trial, best loss: -0.935347568918119]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 0,\n",
       " 'max_depth': 5.498136049182303,\n",
       " 'max_features': 0,\n",
       " 'min_samples_leaf': 0.007264818733396294,\n",
       " 'min_samples_split': 0.05282217977945802,\n",
       " 'n_estimators': 426.84675889453035}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 40, #80\n",
    "            trials = trials)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 1,\n",
       " 'max_depth': 200.0,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 0.043813847274908446,\n",
       " 'min_samples_split': 0.551636834827235,\n",
       " 'n_estimators': 5}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### death from other causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'death_from_other_causes'\n",
    "max_time = 216\n",
    "\n",
    "# mts and bcr have different survival months columns\n",
    "match target_column:\n",
    "    case 'mts':\n",
    "        time = 'survival_months_mts'\n",
    "    case 'bcr':\n",
    "        time = 'survival_months_bcr'\n",
    "    case _:\n",
    "        time = 'survival_months'\n",
    "\n",
    "target_column_discrete = target_column + '_discrete'\n",
    "\n",
    "# List of columns names which will be dropped from feature set before fitting the model\n",
    "target_columns = ['cancer_specific_mortality', 'death_from_other_causes', 'bcr', 'mts']\n",
    "\n",
    "# Explode the dataset\n",
    "df_train_copy_exploded = explode_data(data_train.copy(), min_time=1, max_time=max_time, time=time, target_column=target_column)\n",
    "\n",
    "# Drop targets/features from feature set\n",
    "x_columns_to_drop = [target_column, target_column_discrete, 'survival_months', 'survival_months_bcr', 'survival_months_mts', 'patient_id']\n",
    "x_columns_to_drop.extend(target_columns)\n",
    "X_train = df_train_copy_exploded.drop(x_columns_to_drop, axis=1)    \n",
    "y_train = df_train_copy_exploded[target_column_discrete]\n",
    "\n",
    "df_train_copy_exploded_cumulative = explode_data(data_train.copy(), max_time=max_time, min_time=max_time, cum_event=True, time=time, target_column=target_column)\n",
    "x_columns_to_drop_exploded_cumulative = [target_column+'_discrete', 'survival_months', 'survival_months_bcr', 'survival_months_mts']\n",
    "x_columns_to_drop_exploded_cumulative.extend(target_columns)\n",
    "df_train_copy_exploded_cumulative = df_train_copy_exploded_cumulative.drop(x_columns_to_drop_exploded_cumulative, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
    "        'max_depth': hp.uniform('max_depth',5,20),\n",
    "        'max_features': hp.choice('max_features', ['sqrt','log2', None]),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
    "        'n_estimators' : hp.uniform('n_estimators', 100, 500)\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = int(space['max_depth']),\n",
    "                                 max_features = space['max_features'],\n",
    "                                 min_samples_leaf = space['min_samples_leaf'],\n",
    "                                 min_samples_split = space['min_samples_split'],\n",
    "                                 n_estimators = int(space['n_estimators']), \n",
    "                                 )\n",
    "    \n",
    "    # fit the data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # add predicted probabilities\n",
    "    df_train_copy_exploded_pred = add_predict_probabilities_optimized(df_train_copy_exploded_cumulative.copy(), target_column, model)\n",
    "    \n",
    "    # calculate auc\n",
    "    # AUC for each cumulative slice\n",
    "    # Months at which we'll check the AUC's\n",
    "    months = list(range(6, max_time, 6))\n",
    "\n",
    "    train_auc_stats = []\n",
    "    for month in months:\n",
    "        # --- Training data ---\n",
    "        # Selecting a subset of data based on the months\n",
    "        select = (df_train_copy_exploded_pred['survival_time_discrete'] == month) & pd.notna(df_train_copy_exploded_pred[target_column+'_cumulative'])\n",
    "        sub_dat = df_train_copy_exploded_pred[select]\n",
    "\n",
    "        # If in the sliced data there's a event, calculate AUC metric,\n",
    "        # otherwise assign NaN value\n",
    "        if sub_dat[target_column+'_cumulative'].max() == 1:\n",
    "            fpr, tpr, thresholds = roc_curve(sub_dat[target_column+'_cumulative'], sub_dat['cumulative_hazard'])\n",
    "            auc_stat = auc(fpr, tpr)\n",
    "        else:\n",
    "            auc_stat = float('NaN')\n",
    "        train_auc_stats.append(auc_stat)\n",
    "\n",
    "    auc_mean = np.nanmean(train_auc_stats)\n",
    "\n",
    "    # We aim to maximize auc, therefore we return it as a negative value\n",
    "    return {'loss': -auc_mean, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:12<00:00,  7.24s/trial, best loss: -0.6360188999294815]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 1,\n",
       " 'max_depth': 6.308941631995079,\n",
       " 'max_features': 0,\n",
       " 'min_samples_leaf': 0.25256851781175843,\n",
       " 'min_samples_split': 0.10004228078151234,\n",
       " 'n_estimators': 397.0599160292858}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 10, #80\n",
    "            trials = trials)\n",
    "best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'mts'\n",
    "max_time = 216\n",
    "\n",
    "# mts and bcr have different survival months columns\n",
    "match target_column:\n",
    "    case 'mts':\n",
    "        time = 'survival_months_mts'\n",
    "    case 'bcr':\n",
    "        time = 'survival_months_bcr'\n",
    "    case _:\n",
    "        time = 'survival_months'\n",
    "\n",
    "target_column_discrete = target_column + '_discrete'\n",
    "\n",
    "# List of columns names which will be dropped from feature set before fitting the model\n",
    "target_columns = ['cancer_specific_mortality', 'death_from_other_causes', 'bcr', 'mts']\n",
    "\n",
    "# Explode the dataset\n",
    "df_train_copy_exploded = explode_data(data_train.copy(), min_time=1, max_time=max_time, time=time, target_column=target_column)\n",
    "\n",
    "# Drop targets/features from feature set\n",
    "x_columns_to_drop = [target_column, target_column_discrete, 'survival_months', 'survival_months_bcr', 'survival_months_mts', 'patient_id']\n",
    "x_columns_to_drop.extend(target_columns)\n",
    "X_train = df_train_copy_exploded.drop(x_columns_to_drop, axis=1)    \n",
    "y_train = df_train_copy_exploded[target_column_discrete]\n",
    "\n",
    "df_train_copy_exploded_cumulative = explode_data(data_train.copy(), max_time=max_time, min_time=max_time, cum_event=True, time=time, target_column=target_column)\n",
    "x_columns_to_drop_exploded_cumulative = [target_column+'_discrete', 'survival_months', 'survival_months_bcr', 'survival_months_mts']\n",
    "x_columns_to_drop_exploded_cumulative.extend(target_columns)\n",
    "df_train_copy_exploded_cumulative = df_train_copy_exploded_cumulative.drop(x_columns_to_drop_exploded_cumulative, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
    "        'max_depth': hp.uniform('max_depth',5,20),\n",
    "        'max_features': hp.choice('max_features', ['sqrt','log2', None]),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
    "        'n_estimators' : hp.uniform('n_estimators', 100, 500)\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = int(space['max_depth']),\n",
    "                                 max_features = space['max_features'],\n",
    "                                 min_samples_leaf = space['min_samples_leaf'],\n",
    "                                 min_samples_split = space['min_samples_split'],\n",
    "                                 n_estimators = int(space['n_estimators']), \n",
    "                                 )\n",
    "    \n",
    "    # fit the data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # add predicted probabilities\n",
    "    df_train_copy_exploded_pred = add_predict_probabilities_optimized(df_train_copy_exploded_cumulative.copy(), target_column, model)\n",
    "    \n",
    "    # calculate auc\n",
    "    # AUC for each cumulative slice\n",
    "    # Months at which we'll check the AUC's\n",
    "    months = list(range(6, max_time, 6))\n",
    "\n",
    "    train_auc_stats = []\n",
    "    for month in months:\n",
    "        # --- Training data ---\n",
    "        # Selecting a subset of data based on the months\n",
    "        select = (df_train_copy_exploded_pred['survival_time_discrete'] == month) & pd.notna(df_train_copy_exploded_pred[target_column+'_cumulative'])\n",
    "        sub_dat = df_train_copy_exploded_pred[select]\n",
    "\n",
    "        # If in the sliced data there's a event, calculate AUC metric,\n",
    "        # otherwise assign NaN value\n",
    "        if sub_dat[target_column+'_cumulative'].max() == 1:\n",
    "            fpr, tpr, thresholds = roc_curve(sub_dat[target_column+'_cumulative'], sub_dat['cumulative_hazard'])\n",
    "            auc_stat = auc(fpr, tpr)\n",
    "        else:\n",
    "            auc_stat = float('NaN')\n",
    "        train_auc_stats.append(auc_stat)\n",
    "\n",
    "    auc_mean = np.nanmean(train_auc_stats)\n",
    "\n",
    "    # We aim to maximize auc, therefore we return it as a negative value\n",
    "    return {'loss': -auc_mean, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:15<00:00,  7.58s/trial, best loss: -0.890629556166743]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 1,\n",
       " 'max_depth': 16.810243822100986,\n",
       " 'max_features': 0,\n",
       " 'min_samples_leaf': 0.03125048473423414,\n",
       " 'min_samples_split': 0.22516444376211764,\n",
       " 'n_estimators': 353.6896846350636}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 10, #80\n",
    "            trials = trials)\n",
    "best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'bcr'\n",
    "max_time = 216\n",
    "\n",
    "# mts and bcr have different survival months columns\n",
    "match target_column:\n",
    "    case 'mts':\n",
    "        time = 'survival_months_mts'\n",
    "    case 'bcr':\n",
    "        time = 'survival_months_bcr'\n",
    "    case _:\n",
    "        time = 'survival_months'\n",
    "\n",
    "target_column_discrete = target_column + '_discrete'\n",
    "\n",
    "# List of columns names which will be dropped from feature set before fitting the model\n",
    "target_columns = ['cancer_specific_mortality', 'death_from_other_causes', 'bcr', 'mts']\n",
    "\n",
    "# Explode the dataset\n",
    "df_train_copy_exploded = explode_data(data_train.copy(), min_time=1, max_time=max_time, time=time, target_column=target_column)\n",
    "\n",
    "# Drop targets/features from feature set\n",
    "x_columns_to_drop = [target_column, target_column_discrete, 'survival_months', 'survival_months_bcr', 'survival_months_mts', 'patient_id']\n",
    "x_columns_to_drop.extend(target_columns)\n",
    "X_train = df_train_copy_exploded.drop(x_columns_to_drop, axis=1)    \n",
    "y_train = df_train_copy_exploded[target_column_discrete]\n",
    "\n",
    "df_train_copy_exploded_cumulative = explode_data(data_train.copy(), max_time=max_time, min_time=max_time, cum_event=True, time=time, target_column=target_column)\n",
    "x_columns_to_drop_exploded_cumulative = [target_column+'_discrete', 'survival_months', 'survival_months_bcr', 'survival_months_mts']\n",
    "x_columns_to_drop_exploded_cumulative.extend(target_columns)\n",
    "df_train_copy_exploded_cumulative = df_train_copy_exploded_cumulative.drop(x_columns_to_drop_exploded_cumulative, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
    "        'max_depth': hp.uniform('max_depth',5,20),\n",
    "        'max_features': hp.choice('max_features', ['sqrt','log2', None]),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
    "        'n_estimators' : hp.uniform('n_estimators', 100, 500)\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = int(space['max_depth']),\n",
    "                                 max_features = space['max_features'],\n",
    "                                 min_samples_leaf = space['min_samples_leaf'],\n",
    "                                 min_samples_split = space['min_samples_split'],\n",
    "                                 n_estimators = int(space['n_estimators']), \n",
    "                                 )\n",
    "    \n",
    "    # fit the data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # add predicted probabilities\n",
    "    df_train_copy_exploded_pred = add_predict_probabilities_optimized(df_train_copy_exploded_cumulative.copy(), target_column, model)\n",
    "    \n",
    "    # calculate auc\n",
    "    # AUC for each cumulative slice\n",
    "    # Months at which we'll check the AUC's\n",
    "    months = list(range(6, max_time, 6))\n",
    "\n",
    "    train_auc_stats = []\n",
    "    for month in months:\n",
    "        # --- Training data ---\n",
    "        # Selecting a subset of data based on the months\n",
    "        select = (df_train_copy_exploded_pred['survival_time_discrete'] == month) & pd.notna(df_train_copy_exploded_pred[target_column+'_cumulative'])\n",
    "        sub_dat = df_train_copy_exploded_pred[select]\n",
    "\n",
    "        # If in the sliced data there's a event, calculate AUC metric,\n",
    "        # otherwise assign NaN value\n",
    "        if sub_dat[target_column+'_cumulative'].max() == 1:\n",
    "            fpr, tpr, thresholds = roc_curve(sub_dat[target_column+'_cumulative'], sub_dat['cumulative_hazard'])\n",
    "            auc_stat = auc(fpr, tpr)\n",
    "        else:\n",
    "            auc_stat = float('NaN')\n",
    "        train_auc_stats.append(auc_stat)\n",
    "\n",
    "    auc_mean = np.nanmean(train_auc_stats)\n",
    "\n",
    "    # We aim to maximize auc, therefore we return it as a negative value\n",
    "    return {'loss': -auc_mean, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:16<00:00,  7.69s/trial, best loss: -0.8119986054448181]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 0,\n",
       " 'max_depth': 16.103488534169735,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 0.05973709304919683,\n",
       " 'min_samples_split': 0.09831750690258467,\n",
       " 'n_estimators': 397.0952759650272}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 10, #80\n",
    "            trials = trials)\n",
    "best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
